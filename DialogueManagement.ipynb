{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "345_DialogueManagement.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NQsRmhnh1C4e",
        "outputId": "d1ad1f40-2008-4ead-96ab-76fe2899b8e3"
      },
      "source": [
        "!wget https://gist.githubusercontent.com/bastings/b094de2813da58056a05e8e7950d4ad1/raw/3fbd3976199c2b88de2ae62afc0ecc6f15e6f7ce/glove.840B.300d.sst.txt\r\n"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2021-01-14 07:38:02--  https://gist.githubusercontent.com/bastings/b094de2813da58056a05e8e7950d4ad1/raw/3fbd3976199c2b88de2ae62afc0ecc6f15e6f7ce/glove.840B.300d.sst.txt\n",
            "Resolving gist.githubusercontent.com (gist.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n",
            "Connecting to gist.githubusercontent.com (gist.githubusercontent.com)|151.101.0.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 53933315 (51M) [text/plain]\n",
            "Saving to: ‘glove.840B.300d.sst.txt.1’\n",
            "\n",
            "glove.840B.300d.sst 100%[===================>]  51.43M   136MB/s    in 0.4s    \n",
            "\n",
            "2021-01-14 07:38:02 (136 MB/s) - ‘glove.840B.300d.sst.txt.1’ saved [53933315/53933315]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KtoQOzyz1GZf"
      },
      "source": [
        "!cp glove.840B.300d.sst.txt sample_data/glove.840B.300d.sst.txt"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wkt16Foq1LRB"
      },
      "source": [
        "import pandas as pd\r\n",
        "import numpy as np\r\n",
        "import os\r\n",
        "import pickle\r\n",
        "import numpy as np\r\n",
        "import re\r\n",
        "import itertools\r\n",
        "from collections import Counter\r\n",
        "from keras.callbacks import ModelCheckpoint, EarlyStopping\r\n",
        "from keras.optimizers import *\r\n",
        "from keras.models import Model\r\n",
        "from sklearn.model_selection import train_test_split\r\n",
        "from keras.wrappers.scikit_learn import KerasClassifier\r\n",
        "from numpy import array\r\n",
        "from keras.models import Sequential\r\n",
        "from keras.layers import *\r\n",
        "from keras.preprocessing import sequence\r\n",
        "from keras.regularizers import *\r\n",
        "import tensorflow as tf\r\n",
        "from keras.preprocessing.text import *\r\n",
        "from keras.preprocessing.sequence import pad_sequences\r\n",
        "import timeit"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cp4NS7Ci1QoU"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4gob1qsq1T8P"
      },
      "source": [
        "Constructing training and test datasets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oD3OU2x01Y4H"
      },
      "source": [
        "# Reading the csv file into a pandas dataframe object\r\n",
        "import pandas as pd\r\n",
        "dataset = pd.read_csv('/content/drive/MyDrive/NLP- Assignments/TWEET_DATA_IEEE_TCSS - Sheet1.csv', names=['Tweet', 'Tag'])\r\n"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B7oU1ehp1pVz"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\r\n",
        "\r\n",
        "# split data into train and test set in 80:20 ratio\r\n",
        "train, test = train_test_split(dataset, test_size=0.2, random_state = 12)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XL0OY2Tb1ueP"
      },
      "source": [
        "# holds the test data tweets\r\n",
        "test_data = test['Tweet'].tolist()\r\n",
        "\r\n",
        "# holds the training data tweets\r\n",
        "train_data = train['Tweet'].tolist()\r\n",
        "\r\n",
        "# holds the test data labels\r\n",
        "test_label = test['Tag'].tolist()\r\n",
        "\r\n",
        "# holds the training data labels\r\n",
        "train_label = train['Tag'].tolist()"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s4ENQ-wm1vpc"
      },
      "source": [
        "# holds the entire tweet data\r\n",
        "text_data = dataset['Tweet'].tolist()\r\n",
        "\r\n",
        "# computing the maximum length of the tweets present\r\n",
        "max1=0\r\n",
        "\r\n",
        "for i in range(0,len(text_data)):\r\n",
        "  max2=len(text_data[i])\r\n",
        "  if max2 > max1 :\r\n",
        "    max1 = max2\r\n",
        "\r\n",
        "sequence_length = max1"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IDT8rjJ61zGp"
      },
      "source": [
        "# function to pad additional values so that all vectors are of equal length\r\n",
        "def load_create_padded_data(X_train,maxlen=None):\r\n",
        "  tokenizer = Tokenizer()\r\n",
        "  tokenizer.fit_on_texts(X_train)\r\n",
        "  X_train = tokenizer.texts_to_sequences(X_train)\r\n",
        "  X_train = pad_sequences(X_train,maxlen=maxlen)\r\n",
        "  return X_train"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1uwWx-7I12gz"
      },
      "source": [
        "# constructing padded vectors for the training and testing datasets\r\n",
        "X_train = load_create_padded_data(X_train=train_data,maxlen=sequence_length)\r\n",
        "X_test = load_create_padded_data(X_train=test_data,maxlen=sequence_length)"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LY8WJhSp17-D"
      },
      "source": [
        "# constructing a tokenizer for thr trainig data\r\n",
        "# word_index stores the distinct vocabulary of words that make up the tweets\r\n",
        "tokenizer = Tokenizer()\r\n",
        "tokenizer.fit_on_texts(train_data)\r\n",
        "word_index = tokenizer.word_index"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jba57uaL19Wx"
      },
      "source": [
        "# function to create the embedding matrix\r\n",
        "def load_create_embedding_matrix(word_index,vocab_size,emb_dim,emb_path):\r\n",
        "  embedding_dict = {}\r\n",
        "\r\n",
        "  f = open(emb_path,'rb')\r\n",
        "  for line in f:\r\n",
        "    fields = line.split()\r\n",
        "    word = fields[0]\r\n",
        "    w_e = np.asarray(fields[1:],dtype='float32')\r\n",
        "    embedding_dict[word] = w_e\r\n",
        "  f.close()\r\n",
        "\r\n",
        "  allembs = np.stack(embedding_dict.values())\r\n",
        "  emb_mean,emb_std = allembs.mean(),allembs.std()\r\n",
        "\r\n",
        "  embedding_matrix = np.random.normal(emb_mean,emb_std,(vocab_size,emb_dim))\r\n",
        "\r\n",
        "  for word,index in word_index.items():\r\n",
        "    vector = embedding_dict.get(word)\r\n",
        "    if vector is not None:\r\n",
        "      embedding_matrix[index] = vector\r\n",
        "  \r\n",
        "  return embedding_matrix"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C3MIgGf82Bsa",
        "outputId": "c7fcd238-e9c2-476e-ce8d-e401d142bf5e"
      },
      "source": [
        "# construction of the embedding matrix using the GLOVE embeddings\r\n",
        "embedding_matrix = load_create_embedding_matrix(word_index,len(word_index)+1,300,'./glove.840B.300d.sst.txt')"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py:2882: FutureWarning: arrays to stack must be passed as a \"sequence\" type such as list or tuple. Support for non-sequence iterables such as generators is deprecated as of NumPy 1.16 and will raise an error in the future.\n",
            "  exec(code_obj, self.user_global_ns, self.user_ns)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ydQKVk5b2IfT"
      },
      "source": [
        " #finding the unique set of labels used in the dataset for classification\r\n",
        "label_dict = {}\r\n",
        "index = 0\r\n",
        "\r\n",
        "for label in train_label:\r\n",
        "\tif label not in label_dict:\r\n",
        "\t\tlabel_dict[label] = index\r\n",
        "\t\tindex = index + 1"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W2WkmLfy2QUf"
      },
      "source": [
        "def create_label(label):\r\n",
        "  Y = []\r\n",
        "  for i in label:\r\n",
        "    temp_array = np.zeros(len(label_dict))\r\n",
        "    label_at_i = label_dict.get(i)\r\n",
        "    temp_array[label_at_i] = 1\r\n",
        "    Y.append(temp_array)\r\n",
        "  return Y"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6mW4pK1B2VNU"
      },
      "source": [
        "Y_train = create_label(train_label)\r\n",
        "Y_test = create_label(test_label)\r\n",
        "\r\n",
        "y_train = np.array([i for i in Y_train])\r\n",
        "y_test = np.array([i for i in Y_test])\r\n",
        "\r\n",
        "embedding_dim = 300"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8BPSs9l35LDO"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RHbPX-K94-9m"
      },
      "source": [
        "**Deep Neural Network in Keras using 1-dimensional Convolutional Neural Network (CNN) (Filter size = 32,\r\n",
        "kernel size= 3)**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oj_hNyxS2Y22",
        "outputId": "e1e49c3c-ba5e-4cf4-d80c-e172b3593c59"
      },
      "source": [
        "print(\"Creating Model...\")\r\n",
        "inputs = Input(shape=(sequence_length,), dtype='int32')\r\n",
        "embedding = Embedding(input_dim=len(word_index)+1, output_dim=embedding_dim, weights=[embedding_matrix], input_length=sequence_length)(inputs)\r\n",
        "conv_0 = Conv1D(filters=32, kernel_size=3, padding='same', kernel_initializer='normal', activation='relu')(embedding)\r\n",
        "maxpool_0 = MaxPooling1D(pool_size=2)(conv_0)\r\n",
        "dropout = Dropout(0.1)(maxpool_0)\r\n",
        "conv_1 = Conv1D(filters=64, kernel_size=3, padding='same', kernel_initializer='normal', activation='relu')(dropout)\r\n",
        "maxpool_1 = MaxPooling1D(pool_size=2)(conv_1)\r\n",
        "flatten = Flatten()(maxpool_1)\r\n",
        "predictions = Dense(1000, activation='relu')(flatten)\r\n",
        "predictions1 = Dense(len(label_dict), activation='softmax')(predictions)\r\n",
        "adam = Adam(lr=0.01, decay=0.3)\r\n",
        "model = Model(inputs=inputs, outputs=predictions1)\r\n",
        "model.compile(optimizer=adam, loss='categorical_crossentropy', metrics=['accuracy'])\r\n",
        "model.fit(X_train, y_train, epochs=30, batch_size=64, validation_data=(X_test, y_test))\r\n",
        "\r\n",
        "\r\n",
        "predicted = model.predict(X_test)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Creating Model...\n",
            "Epoch 1/30\n",
            "94/94 [==============================] - 22s 220ms/step - loss: 11.9375 - accuracy: 0.4714 - val_loss: 1.4420 - val_accuracy: 0.5140\n",
            "Epoch 2/30\n",
            "94/94 [==============================] - 20s 217ms/step - loss: 1.3990 - accuracy: 0.5278 - val_loss: 1.4283 - val_accuracy: 0.5140\n",
            "Epoch 3/30\n",
            "94/94 [==============================] - 20s 216ms/step - loss: 1.3790 - accuracy: 0.5341 - val_loss: 1.4215 - val_accuracy: 0.5140\n",
            "Epoch 4/30\n",
            "94/94 [==============================] - 25s 268ms/step - loss: 1.3289 - accuracy: 0.5329 - val_loss: 1.4255 - val_accuracy: 0.5140\n",
            "Epoch 5/30\n",
            "94/94 [==============================] - 20s 218ms/step - loss: 1.2910 - accuracy: 0.5471 - val_loss: 1.4261 - val_accuracy: 0.5140\n",
            "Epoch 6/30\n",
            "94/94 [==============================] - 20s 216ms/step - loss: 1.2674 - accuracy: 0.5739 - val_loss: 1.4392 - val_accuracy: 0.5140\n",
            "Epoch 7/30\n",
            "94/94 [==============================] - 20s 217ms/step - loss: 1.2413 - accuracy: 0.6056 - val_loss: 1.4490 - val_accuracy: 0.5133\n",
            "Epoch 8/30\n",
            "94/94 [==============================] - 20s 214ms/step - loss: 1.1986 - accuracy: 0.6266 - val_loss: 1.4734 - val_accuracy: 0.5140\n",
            "Epoch 9/30\n",
            "94/94 [==============================] - 20s 216ms/step - loss: 1.1879 - accuracy: 0.6157 - val_loss: 1.4666 - val_accuracy: 0.5127\n",
            "Epoch 10/30\n",
            "94/94 [==============================] - 20s 219ms/step - loss: 1.1684 - accuracy: 0.6321 - val_loss: 1.4682 - val_accuracy: 0.5113\n",
            "Epoch 11/30\n",
            "94/94 [==============================] - 20s 214ms/step - loss: 1.1441 - accuracy: 0.6443 - val_loss: 1.4701 - val_accuracy: 0.5113\n",
            "Epoch 12/30\n",
            "94/94 [==============================] - 20s 214ms/step - loss: 1.1301 - accuracy: 0.6382 - val_loss: 1.4851 - val_accuracy: 0.5113\n",
            "Epoch 13/30\n",
            "94/94 [==============================] - 20s 213ms/step - loss: 1.1084 - accuracy: 0.6533 - val_loss: 1.4844 - val_accuracy: 0.5107\n",
            "Epoch 14/30\n",
            "94/94 [==============================] - 20s 214ms/step - loss: 1.1156 - accuracy: 0.6453 - val_loss: 1.4911 - val_accuracy: 0.5113\n",
            "Epoch 15/30\n",
            "94/94 [==============================] - 20s 215ms/step - loss: 1.0950 - accuracy: 0.6559 - val_loss: 1.5062 - val_accuracy: 0.5113\n",
            "Epoch 16/30\n",
            "94/94 [==============================] - 20s 216ms/step - loss: 1.0881 - accuracy: 0.6539 - val_loss: 1.5062 - val_accuracy: 0.5093\n",
            "Epoch 17/30\n",
            "94/94 [==============================] - 20s 209ms/step - loss: 1.1121 - accuracy: 0.6527 - val_loss: 1.5315 - val_accuracy: 0.5107\n",
            "Epoch 18/30\n",
            "94/94 [==============================] - 20s 214ms/step - loss: 1.0735 - accuracy: 0.6572 - val_loss: 1.5253 - val_accuracy: 0.5120\n",
            "Epoch 19/30\n",
            "94/94 [==============================] - 20s 216ms/step - loss: 1.0451 - accuracy: 0.6761 - val_loss: 1.5121 - val_accuracy: 0.5040\n",
            "Epoch 20/30\n",
            "94/94 [==============================] - 20s 215ms/step - loss: 1.0724 - accuracy: 0.6605 - val_loss: 1.5349 - val_accuracy: 0.5100\n",
            "Epoch 21/30\n",
            "94/94 [==============================] - 20s 212ms/step - loss: 1.0686 - accuracy: 0.6550 - val_loss: 1.5361 - val_accuracy: 0.5053\n",
            "Epoch 22/30\n",
            "94/94 [==============================] - 20s 214ms/step - loss: 1.0253 - accuracy: 0.6804 - val_loss: 1.5347 - val_accuracy: 0.5040\n",
            "Epoch 23/30\n",
            "94/94 [==============================] - 20s 213ms/step - loss: 1.0537 - accuracy: 0.6665 - val_loss: 1.5301 - val_accuracy: 0.5033\n",
            "Epoch 24/30\n",
            "94/94 [==============================] - 20s 215ms/step - loss: 1.0139 - accuracy: 0.6796 - val_loss: 1.5413 - val_accuracy: 0.5033\n",
            "Epoch 25/30\n",
            "94/94 [==============================] - 20s 213ms/step - loss: 1.0610 - accuracy: 0.6633 - val_loss: 1.5380 - val_accuracy: 0.5033\n",
            "Epoch 26/30\n",
            "94/94 [==============================] - 20s 211ms/step - loss: 1.0247 - accuracy: 0.6731 - val_loss: 1.5414 - val_accuracy: 0.5033\n",
            "Epoch 27/30\n",
            "94/94 [==============================] - 20s 211ms/step - loss: 0.9970 - accuracy: 0.6825 - val_loss: 1.5613 - val_accuracy: 0.5040\n",
            "Epoch 28/30\n",
            "94/94 [==============================] - 20s 211ms/step - loss: 1.0263 - accuracy: 0.6747 - val_loss: 1.5459 - val_accuracy: 0.5013\n",
            "Epoch 29/30\n",
            "94/94 [==============================] - 20s 210ms/step - loss: 1.0172 - accuracy: 0.6770 - val_loss: 1.5537 - val_accuracy: 0.5013\n",
            "Epoch 30/30\n",
            "94/94 [==============================] - 20s 212ms/step - loss: 1.0155 - accuracy: 0.6769 - val_loss: 1.5516 - val_accuracy: 0.5020\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C9kQlP0Q5Tzn",
        "outputId": "8528dbe6-f575-4de9-c6db-705e8d58f93d"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_1 (InputLayer)         [(None, 310)]             0         \n",
            "_________________________________________________________________\n",
            "embedding (Embedding)        (None, 310, 300)          4563600   \n",
            "_________________________________________________________________\n",
            "conv1d (Conv1D)              (None, 310, 32)           28832     \n",
            "_________________________________________________________________\n",
            "max_pooling1d (MaxPooling1D) (None, 155, 32)           0         \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 155, 32)           0         \n",
            "_________________________________________________________________\n",
            "conv1d_1 (Conv1D)            (None, 155, 64)           6208      \n",
            "_________________________________________________________________\n",
            "max_pooling1d_1 (MaxPooling1 (None, 77, 64)            0         \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 4928)              0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 1000)              4929000   \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 7)                 7007      \n",
            "=================================================================\n",
            "Total params: 9,534,647\n",
            "Trainable params: 9,534,647\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "50rdyGaA5Vi6",
        "outputId": "6ca88588-2a5f-4dd4-b33e-12d3d7b20cd8"
      },
      "source": [
        "Y_predicted=[]\r\n",
        "for i in predicted:\r\n",
        "    pos=i.argmax()\r\n",
        "    Y_predicted.append(pos)\r\n",
        "    \r\n",
        "    \r\n",
        "    \r\n",
        "Y_test=[]\r\n",
        "for i in y_test:\r\n",
        "    pos=i.argmax()\r\n",
        "    Y_test.append(pos)\r\n",
        "    \r\n",
        "    \r\n",
        "    \r\n",
        "from sklearn.metrics import accuracy_score\r\n",
        "from sklearn.metrics import confusion_matrix\r\n",
        "from sklearn.metrics import classification_report\r\n",
        "\r\n",
        "print(\"\\nAccuracy Score : \\n\\n\", accuracy_score(Y_test, Y_predicted))\r\n",
        "print(\"\\nClassification Report : \\n\\n\", classification_report(Y_test, Y_predicted,digits=4,))\r\n",
        "print(\"\\nConfusion Matrix : \\n\\n\", confusion_matrix(Y_test, Y_predicted))"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Accuracy Score : \n",
            "\n",
            " 0.502\n",
            "\n",
            "Classification Report : \n",
            "\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0     0.0000    0.0000    0.0000        82\n",
            "           1     0.5205    0.9533    0.6734       771\n",
            "           2     0.2045    0.0516    0.0824       349\n",
            "           3     0.0000    0.0000    0.0000       118\n",
            "           4     0.0000    0.0000    0.0000        53\n",
            "           5     0.0000    0.0000    0.0000        48\n",
            "           6     0.0000    0.0000    0.0000        79\n",
            "\n",
            "    accuracy                         0.5020      1500\n",
            "   macro avg     0.1036    0.1436    0.1080      1500\n",
            "weighted avg     0.3151    0.5020    0.3653      1500\n",
            "\n",
            "\n",
            "Confusion Matrix : \n",
            "\n",
            " [[  0  74   8   0   0   0   0]\n",
            " [  0 735  36   0   0   0   0]\n",
            " [  0 331  18   0   0   0   0]\n",
            " [  0 110   8   0   0   0   0]\n",
            " [  0  47   6   0   0   0   0]\n",
            " [  0  46   2   0   0   0   0]\n",
            " [  0  69  10   0   0   0   0]]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SKpvW3qB54Ba"
      },
      "source": [
        "\r\n",
        "**Deep Neural Network in Keras using Using Bi-directional Long Short Term Memory Network (Bi-LSTM) (72 units each)**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "alI0CRq15byV",
        "outputId": "35920848-846e-4729-9cad-19799abcd472"
      },
      "source": [
        "from tensorflow import keras\r\n",
        "from tensorflow.keras import layers\r\n",
        "\r\n",
        "# Input for variable-length sequences of integers\r\n",
        "inputs = keras.Input(shape=(None,), dtype=\"int32\")\r\n",
        "# Embed each integer in a 128-dimensional vector\r\n",
        "x = layers.Embedding(len(word_index)+1, 128)(inputs)\r\n",
        "# Add 2 bidirectional LSTMs\r\n",
        "x = layers.Bidirectional(layers.LSTM(72, return_sequences=True))(x)\r\n",
        "x = layers.Bidirectional(layers.LSTM(72))(x)\r\n",
        "# Add a classifier\r\n",
        "outputs = layers.Dense(1, activation=\"sigmoid\")(x)\r\n",
        "Bi_LSTM_model = keras.Model(inputs, outputs)\r\n",
        "Bi_LSTM_model.summary()"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_2 (InputLayer)         [(None, None)]            0         \n",
            "_________________________________________________________________\n",
            "embedding_1 (Embedding)      (None, None, 128)         1947136   \n",
            "_________________________________________________________________\n",
            "bidirectional (Bidirectional (None, None, 144)         115776    \n",
            "_________________________________________________________________\n",
            "bidirectional_1 (Bidirection (None, 144)               124992    \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 1)                 145       \n",
            "=================================================================\n",
            "Total params: 2,188,049\n",
            "Trainable params: 2,188,049\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yGq2qFuG5ngd",
        "outputId": "c4f01846-a372-4b84-98d8-3bb7cff668dd"
      },
      "source": [
        "model.compile(\"adam\", \"binary_crossentropy\", metrics=[\"accuracy\"])\r\n",
        "model.fit(X_train, y_train, batch_size=32, epochs=30, validation_data=(X_test, y_test))\r\n",
        "predicted_new = model.predict(X_test)"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/30\n",
            "188/188 [==============================] - 25s 132ms/step - loss: 0.3302 - accuracy: 0.6400 - val_loss: 0.3479 - val_accuracy: 0.4787\n",
            "Epoch 2/30\n",
            "188/188 [==============================] - 25s 131ms/step - loss: 0.1925 - accuracy: 0.7333 - val_loss: 0.3936 - val_accuracy: 0.4380\n",
            "Epoch 3/30\n",
            "188/188 [==============================] - 25s 131ms/step - loss: 0.1397 - accuracy: 0.8006 - val_loss: 0.4645 - val_accuracy: 0.4667\n",
            "Epoch 4/30\n",
            "188/188 [==============================] - 25s 132ms/step - loss: 0.0898 - accuracy: 0.8867 - val_loss: 0.4890 - val_accuracy: 0.4147\n",
            "Epoch 5/30\n",
            "188/188 [==============================] - 24s 130ms/step - loss: 0.0618 - accuracy: 0.9273 - val_loss: 0.5346 - val_accuracy: 0.4107\n",
            "Epoch 6/30\n",
            "188/188 [==============================] - 25s 132ms/step - loss: 0.0444 - accuracy: 0.9532 - val_loss: 0.6272 - val_accuracy: 0.4200\n",
            "Epoch 7/30\n",
            "188/188 [==============================] - 25s 132ms/step - loss: 0.0337 - accuracy: 0.9643 - val_loss: 0.6074 - val_accuracy: 0.4087\n",
            "Epoch 8/30\n",
            "188/188 [==============================] - 25s 131ms/step - loss: 0.0273 - accuracy: 0.9715 - val_loss: 0.6883 - val_accuracy: 0.4313\n",
            "Epoch 9/30\n",
            "188/188 [==============================] - 25s 131ms/step - loss: 0.0234 - accuracy: 0.9714 - val_loss: 0.6142 - val_accuracy: 0.3833\n",
            "Epoch 10/30\n",
            "188/188 [==============================] - 25s 132ms/step - loss: 0.0207 - accuracy: 0.9758 - val_loss: 0.6892 - val_accuracy: 0.4120\n",
            "Epoch 11/30\n",
            "188/188 [==============================] - 25s 134ms/step - loss: 0.0156 - accuracy: 0.9798 - val_loss: 0.7029 - val_accuracy: 0.3893\n",
            "Epoch 12/30\n",
            "188/188 [==============================] - 25s 131ms/step - loss: 0.0177 - accuracy: 0.9752 - val_loss: 0.7282 - val_accuracy: 0.3960\n",
            "Epoch 13/30\n",
            "188/188 [==============================] - 25s 131ms/step - loss: 0.0168 - accuracy: 0.9776 - val_loss: 0.6470 - val_accuracy: 0.3787\n",
            "Epoch 14/30\n",
            "188/188 [==============================] - 25s 131ms/step - loss: 0.0147 - accuracy: 0.9786 - val_loss: 0.7364 - val_accuracy: 0.3873\n",
            "Epoch 15/30\n",
            "188/188 [==============================] - 25s 130ms/step - loss: 0.0137 - accuracy: 0.9798 - val_loss: 0.7595 - val_accuracy: 0.3427\n",
            "Epoch 16/30\n",
            "188/188 [==============================] - 25s 132ms/step - loss: 0.0142 - accuracy: 0.9762 - val_loss: 0.7957 - val_accuracy: 0.3833\n",
            "Epoch 17/30\n",
            "188/188 [==============================] - 25s 132ms/step - loss: 0.0137 - accuracy: 0.9765 - val_loss: 0.8174 - val_accuracy: 0.3900\n",
            "Epoch 18/30\n",
            "188/188 [==============================] - 25s 131ms/step - loss: 0.0127 - accuracy: 0.9795 - val_loss: 0.8067 - val_accuracy: 0.4047\n",
            "Epoch 19/30\n",
            "188/188 [==============================] - 24s 129ms/step - loss: 0.0146 - accuracy: 0.9764 - val_loss: 0.8831 - val_accuracy: 0.4127\n",
            "Epoch 20/30\n",
            "188/188 [==============================] - 25s 133ms/step - loss: 0.0123 - accuracy: 0.9776 - val_loss: 0.8235 - val_accuracy: 0.3953\n",
            "Epoch 21/30\n",
            "188/188 [==============================] - 25s 133ms/step - loss: 0.0128 - accuracy: 0.9786 - val_loss: 0.9486 - val_accuracy: 0.4033\n",
            "Epoch 22/30\n",
            "188/188 [==============================] - 25s 132ms/step - loss: 0.0125 - accuracy: 0.9793 - val_loss: 0.9241 - val_accuracy: 0.3900\n",
            "Epoch 23/30\n",
            "188/188 [==============================] - 25s 130ms/step - loss: 0.0122 - accuracy: 0.9797 - val_loss: 0.8259 - val_accuracy: 0.3500\n",
            "Epoch 24/30\n",
            "188/188 [==============================] - 25s 133ms/step - loss: 0.0156 - accuracy: 0.9773 - val_loss: 0.7236 - val_accuracy: 0.3940\n",
            "Epoch 25/30\n",
            "188/188 [==============================] - 25s 131ms/step - loss: 0.0119 - accuracy: 0.9782 - val_loss: 0.8712 - val_accuracy: 0.3767\n",
            "Epoch 26/30\n",
            "188/188 [==============================] - 25s 131ms/step - loss: 0.0119 - accuracy: 0.9790 - val_loss: 0.9562 - val_accuracy: 0.3653\n",
            "Epoch 27/30\n",
            "188/188 [==============================] - 25s 132ms/step - loss: 0.0086 - accuracy: 0.9838 - val_loss: 0.9404 - val_accuracy: 0.3913\n",
            "Epoch 28/30\n",
            "188/188 [==============================] - 25s 132ms/step - loss: 0.0113 - accuracy: 0.9794 - val_loss: 0.7903 - val_accuracy: 0.3820\n",
            "Epoch 29/30\n",
            "188/188 [==============================] - 25s 132ms/step - loss: 0.0099 - accuracy: 0.9822 - val_loss: 1.0013 - val_accuracy: 0.3780\n",
            "Epoch 30/30\n",
            "188/188 [==============================] - 25s 132ms/step - loss: 0.0099 - accuracy: 0.9817 - val_loss: 1.0242 - val_accuracy: 0.4027\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fb1cyh1R5tx-",
        "outputId": "10b7ca72-8b1a-4d1b-db2e-fc39bd4e604f"
      },
      "source": [
        "Y_predicted_new = []\r\n",
        "for i in predicted_new:\r\n",
        "    pos=i.argmax()\r\n",
        "    Y_predicted_new.append(pos)\r\n",
        "    \r\n",
        "    \r\n",
        "    \r\n",
        "Y_test_new = []\r\n",
        "for i in y_test:\r\n",
        "    pos = i.argmax()\r\n",
        "    Y_test_new.append(pos)\r\n",
        "    \r\n",
        "    \r\n",
        "    \r\n",
        "from sklearn.metrics import accuracy_score\r\n",
        "from sklearn.metrics import confusion_matrix\r\n",
        "from sklearn.metrics import classification_report\r\n",
        "\r\n",
        "print(\"\\nAccuracy Score : \\n\\n\", accuracy_score(Y_test, Y_predicted_new))\r\n",
        "print(\"\\nClassification Report : \\n\\n\", classification_report(Y_test, Y_predicted_new,digits=4,))\r\n",
        "print(\"\\nConfusion Matrix : \\n\\n\", confusion_matrix(Y_test, Y_predicted_new))"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Accuracy Score : \n",
            "\n",
            " 0.4026666666666667\n",
            "\n",
            "Classification Report : \n",
            "\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0     0.2143    0.0732    0.1091        82\n",
            "           1     0.5204    0.6783    0.5890       771\n",
            "           2     0.1658    0.0946    0.1204       349\n",
            "           3     0.0842    0.0678    0.0751       118\n",
            "           4     0.0000    0.0000    0.0000        53\n",
            "           5     0.0000    0.0000    0.0000        48\n",
            "           6     0.2446    0.4304    0.3119        79\n",
            "\n",
            "    accuracy                         0.4027      1500\n",
            "   macro avg     0.1756    0.1920    0.1722      1500\n",
            "weighted avg     0.3373    0.4027    0.3591      1500\n",
            "\n",
            "\n",
            "Confusion Matrix : \n",
            "\n",
            " [[  6  40  18   5   0   6   7]\n",
            " [ 10 523 103  60   5  14  56]\n",
            " [  8 264  33  17   2   3  22]\n",
            " [  1  76  19   8   1   2  11]\n",
            " [  3  38   8   2   0   1   1]\n",
            " [  0  33   5   2   0   0   8]\n",
            " [  0  31  13   1   0   0  34]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5ia5DkOAFkbR"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "18UTyEGGFmfF"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2bbGjmk1Fk3t"
      },
      "source": [
        "**Wrong matched Sentences- CNN model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NxMT4tI6FuOf"
      },
      "source": [
        "tag_numbers = {}\r\n",
        "for key, value in label_dict.items():\r\n",
        "  tag_numbers[value] = key"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C7nwWjMKFy8q"
      },
      "source": [
        "index_of_difference_new = []\r\n",
        "for i in range(0, len(Y_predicted_new)):\r\n",
        "  if Y_predicted_new[i] != Y_test_new[i]:\r\n",
        "    index_of_difference_new.append((i, Y_test_new[i], Y_predicted_new[i]))"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V5kkTGC-F3ez"
      },
      "source": [
        "difference_dataframe_new = pd.DataFrame(columns={'Tweet', 'Actual Tag', 'Predicted Tag'})\r\n",
        "for elt in index_of_difference_new:\r\n",
        "  difference_dataframe_new = difference_dataframe_new.append({'Tweet' : dataset['Tweet'][elt[0]], 'Actual Tag' : tag_numbers[elt[1]], 'Predicted Tag' : tag_numbers[elt[2]]}, ignore_index=True)"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 415
        },
        "id": "e-6vo_apGBtH",
        "outputId": "2fecc00e-4d44-4d3d-be8b-fc87fa8d85fd"
      },
      "source": [
        "difference_dataframe_new"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Tweet</th>\n",
              "      <th>Actual Tag</th>\n",
              "      <th>Predicted Tag</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>RT @stevesilberman: If you missed it: Sick bur...</td>\n",
              "      <td>QUE</td>\n",
              "      <td>STM</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>@jk_rowling &amp; the Never-Ending Story: With a #...</td>\n",
              "      <td>STM</td>\n",
              "      <td>EXP</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>RT @somebadideas: The emotional &amp; personal eff...</td>\n",
              "      <td>REQ</td>\n",
              "      <td>OTH</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>RT @jk_rowling: A 9-year-old Nigerian girl has...</td>\n",
              "      <td>EXP</td>\n",
              "      <td>OTH</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>RT @jk_rowling: I don't want to say too much m...</td>\n",
              "      <td>STM</td>\n",
              "      <td>OTH</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>891</th>\n",
              "      <td>Sweet is a comic book fan from way back...He's...</td>\n",
              "      <td>STM</td>\n",
              "      <td>EXP</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>892</th>\n",
              "      <td>@naomi0_0barton You mean Ursula Le Guin? She i...</td>\n",
              "      <td>SUG</td>\n",
              "      <td>EXP</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>893</th>\n",
              "      <td>Hard times are coming. We'll need writers who ...</td>\n",
              "      <td>STM</td>\n",
              "      <td>QUE</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>894</th>\n",
              "      <td>@alsotheabyss Left Hand of Darkness too, but L...</td>\n",
              "      <td>SUG</td>\n",
              "      <td>STM</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>895</th>\n",
              "      <td>The secret to choose what ever seen. Maybe exp...</td>\n",
              "      <td>STM</td>\n",
              "      <td>EXP</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>896 rows × 3 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                 Tweet Actual Tag Predicted Tag\n",
              "0    RT @stevesilberman: If you missed it: Sick bur...        QUE           STM\n",
              "1    @jk_rowling & the Never-Ending Story: With a #...        STM           EXP\n",
              "2    RT @somebadideas: The emotional & personal eff...        REQ           OTH\n",
              "3    RT @jk_rowling: A 9-year-old Nigerian girl has...        EXP           OTH\n",
              "4    RT @jk_rowling: I don't want to say too much m...        STM           OTH\n",
              "..                                                 ...        ...           ...\n",
              "891  Sweet is a comic book fan from way back...He's...        STM           EXP\n",
              "892  @naomi0_0barton You mean Ursula Le Guin? She i...        SUG           EXP\n",
              "893  Hard times are coming. We'll need writers who ...        STM           QUE\n",
              "894  @alsotheabyss Left Hand of Darkness too, but L...        SUG           STM\n",
              "895  The secret to choose what ever seen. Maybe exp...        STM           EXP\n",
              "\n",
              "[896 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    }
  ]
}