{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Arushi Sharma - Word2Vec_Task2.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PwwkpADKyeUS"
      },
      "source": [
        "# Importing all the necessary Libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mCRuJpTJycIv",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "outputId": "48600e2d-b697-4a3a-b7eb-c5c3b2a0c2ef"
      },
      "source": [
        "from nltk.corpus import reuters \r\n",
        "from sklearn.preprocessing import MultiLabelBinarizer\r\n",
        "import pandas as pd\r\n",
        "import spacy\r\n",
        "import numpy as np\r\n",
        "\r\n",
        "'''\r\n",
        "  https://scikit-learn.org/stable/modules/generated/sklearn.naive_bayes.GaussianNB.html\r\n",
        "  https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html\r\n",
        "  https://spacy.io/usage/vectors-similarity\r\n",
        "'''"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'\\n  https://scikit-learn.org/stable/modules/generated/sklearn.naive_bayes.GaussianNB.html\\n  https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html\\n  https://spacy.io/usage/vectors-similarity\\n'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xm9uz654ye-7",
        "outputId": "66e38737-f669-4d1e-d220-176698ae3c34"
      },
      "source": [
        "import nltk\r\n",
        "nltk.download('reuters')\r\n",
        "!python -m spacy download en_core_web_lg"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package reuters to /root/nltk_data...\n",
            "[nltk_data]   Package reuters is already up-to-date!\n",
            "Requirement already satisfied: en_core_web_lg==2.2.5 from https://github.com/explosion/spacy-models/releases/download/en_core_web_lg-2.2.5/en_core_web_lg-2.2.5.tar.gz#egg=en_core_web_lg==2.2.5 in /usr/local/lib/python3.6/dist-packages (2.2.5)\n",
            "Requirement already satisfied: spacy>=2.2.2 in /usr/local/lib/python3.6/dist-packages (from en_core_web_lg==2.2.5) (2.2.4)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_lg==2.2.5) (51.1.1)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_lg==2.2.5) (3.0.5)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_lg==2.2.5) (0.8.0)\n",
            "Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_lg==2.2.5) (1.0.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_lg==2.2.5) (1.0.5)\n",
            "Requirement already satisfied: thinc==7.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_lg==2.2.5) (7.4.0)\n",
            "Requirement already satisfied: blis<0.5.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_lg==2.2.5) (0.4.1)\n",
            "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_lg==2.2.5) (1.0.0)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_lg==2.2.5) (1.19.5)\n",
            "Requirement already satisfied: plac<1.2.0,>=0.9.6 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_lg==2.2.5) (1.1.3)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_lg==2.2.5) (2.23.0)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_lg==2.2.5) (2.0.5)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_lg==2.2.5) (4.41.1)\n",
            "Requirement already satisfied: importlib-metadata>=0.20; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->en_core_web_lg==2.2.5) (3.3.0)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_lg==2.2.5) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_lg==2.2.5) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_lg==2.2.5) (2020.12.5)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_lg==2.2.5) (3.0.4)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->en_core_web_lg==2.2.5) (3.4.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->en_core_web_lg==2.2.5) (3.7.4.3)\n",
            "\u001b[38;5;2mâœ” Download and installation successful\u001b[0m\n",
            "You can now load the model via spacy.load('en_core_web_lg')\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fVJkzlpoygxe",
        "outputId": "1f29a9a0-6a42-4732-cd3d-27cb29fa0c38"
      },
      "source": [
        "import nltk\r\n",
        "nltk.download('stopwords')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8HgMwpI0ylJP",
        "outputId": "b34aa44b-f613-4713-bf44-a5300c44c1c4"
      },
      "source": [
        "import nltk\r\n",
        "nltk.download('punkt')\r\n",
        "  "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BNhgkF0q0WT_"
      },
      "source": [
        "# Loading Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VlWL3zjlzvVQ"
      },
      "source": [
        "mlb = MultiLabelBinarizer()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4dN0IKFN1NgR"
      },
      "source": [
        "def collection_stats():\r\n",
        "  documents = reuters.fileids()\r\n",
        "  print(str(len(documents)) + \" documents\");\r\n",
        "\r\n",
        "  train_docs = list(filter(lambda doc: doc.startswith(\"train\"), documents));\r\n",
        "  print(str(len(train_docs)) + \" total train documents\");\r\n",
        " \r\n",
        "  test_docs = list(filter(lambda doc: doc.startswith(\"test\"), documents));\r\n",
        "  print(str(len(test_docs)) + \" total test documents\")\r\n",
        "\r\n",
        "  categories = reuters.categories()\r\n",
        "\r\n",
        "  print(str(len(categories)) + \" categories\");"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RfBPxUot1e9s",
        "outputId": "29913dd9-7c17-43c1-c596-42b2ca30b3a6"
      },
      "source": [
        "collection_stats()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "10788 documents\n",
            "7769 total train documents\n",
            "3019 total test documents\n",
            "90 categories\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GIl-WZB91i6U"
      },
      "source": [
        "# Train Test Split of Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TjsuV-8O1gXp"
      },
      "source": [
        "def train_test_split():\r\n",
        "  documents = reuters.fileids()\r\n",
        "  train_docs = [document for document in documents if document.startswith(\"train\")]\r\n",
        "  test_docs = [document for document in documents if document.startswith(\"test\")]\r\n",
        "  x_train = [reuters.raw(doc_id) for doc_id in train_docs]\r\n",
        "  y_train = [reuters.raw(doc_id) for doc_id in test_docs]\r\n",
        "  x_test = mlb.fit_transform([reuters.categories(doc_id) for doc_id in train_docs])\r\n",
        "  y_test = mlb.transform([reuters.categories(doc_id) for doc_id in test_docs])\r\n",
        "  return x_train, y_train, x_test, y_test"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3fobAnGh1lYA"
      },
      "source": [
        "x_train, x_test, y_train, y_test = train_test_split()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aozDGMZL1pR4"
      },
      "source": [
        "# Data Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x9S5IqN31m5z"
      },
      "source": [
        "import re\r\n",
        "import nltk\r\n",
        "from nltk.tokenize import word_tokenize\r\n",
        "from nltk.corpus import stopwords"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IHTHz5OS11KR"
      },
      "source": [
        "stop_words = set(stopwords.words('english'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dPkbzO9-1sJD"
      },
      "source": [
        "def clean_text(X_train):\r\n",
        "   ret =[]\r\n",
        "   for x_pre in X_train:\r\n",
        "    x_pre = re.sub(r'https\\S+','', x_pre)\r\n",
        "\r\n",
        "    x_pre = re.sub('[^a-zA-Z]','', x_pre)\r\n",
        "    x_pre = str(x_pre).lower()\r\n",
        "    x_pre = word_tokenize(x_pre)\r\n",
        "    x_pre = [item for item in x_pre if item not in stop_words]\r\n",
        "    x_pre = ' '.join(x_pre)\r\n",
        "    ret.append(x_pre)\r\n",
        "   return ret \r\n",
        " \r\n",
        "  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EvZpciiv1uHK"
      },
      "source": [
        "X_train=clean_text(x_train)\r\n",
        "X_test =clean_text(x_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HW-AP9OF16U8"
      },
      "source": [
        "# Word2Vec Representation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PA0hQ43Z2cVb"
      },
      "source": [
        "nlp = spacy.load(\"en_core_web_lg\")\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2apRo7SF1-Kb"
      },
      "source": [
        "def get_word_vectors(sentence):\r\n",
        " \r\n",
        " tokens = nlp(sentence)\r\n",
        " vector = np.sum([token.vector for token in tokens], axis =0)\r\n",
        " return vector"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XEp5fOQ_LH_g"
      },
      "source": [
        "## Generate Word2Vec embeddings for training data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "15Q3ppy4IF_c",
        "outputId": "cdca2c3f-4887-43e2-e2de-ef19465f99aa"
      },
      "source": [
        "x_train = [get_word_vectors(doc) for doc in x_train]\r\n",
        "print(np.shape(x_train))\r\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(7769, 300)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6pExa8RTLRgv"
      },
      "source": [
        "## Generate Word2Vec embeddings for testing data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KME2ROFrH4zv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ff323687-b84b-43c5-99e7-2eaf36f95bb2"
      },
      "source": [
        "x_test = [get_word_vectors(doc) for doc in x_test]\r\n",
        "print(np.shape(x_test))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(3019, 300)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ue2jfi1D433s"
      },
      "source": [
        "# Logistic Regression "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7B_oYpcC3spK"
      },
      "source": [
        "from sklearn.linear_model import LogisticRegression\r\n",
        "from sklearn.multiclass import OneVsRestClassifier\r\n",
        "from sklearn.metrics import classification_report"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E7PhwrmvLYys"
      },
      "source": [
        "## Fit and Predict Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BvwJ4JJQhvMY",
        "outputId": "86b68d0e-4496-46b9-d762-f26cc4a51734"
      },
      "source": [
        "len(x_train)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "7769"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 62
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0Dj0yGIXhziT",
        "outputId": "85ea1d97-3d41-4822-b6aa-00eef41593eb"
      },
      "source": [
        "len(y_train)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "7769"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 63
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tb6XcGmS5VO2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f669e323-b3b0-45fe-f119-9085b0419b61"
      },
      "source": [
        "lr = OneVsRestClassifier(LogisticRegression(solver ='newton-cg'))\r\n",
        "lr.fit(x_train, y_train)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "OneVsRestClassifier(estimator=LogisticRegression(C=1.0, class_weight=None,\n",
              "                                                 dual=False, fit_intercept=True,\n",
              "                                                 intercept_scaling=1,\n",
              "                                                 l1_ratio=None, max_iter=100,\n",
              "                                                 multi_class='auto',\n",
              "                                                 n_jobs=None, penalty='l2',\n",
              "                                                 random_state=None,\n",
              "                                                 solver='newton-cg', tol=0.0001,\n",
              "                                                 verbose=0, warm_start=False),\n",
              "                    n_jobs=None)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 64
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RoQXdO4a5XFx"
      },
      "source": [
        "y_pred = lr.predict(x_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0fLv0ZMBLeZH"
      },
      "source": [
        "## Classification report on testing data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yylwQMfs55js",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "171a5d2f-611f-48eb-e47d-016fb1cd27d5"
      },
      "source": [
        "print(\"Word2vec Result word on Train\")\r\n",
        "print(classification_report(y_pred=y_pred , y_true=y_test))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Word2vec Result word on Train\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.94      0.91      0.92       719\n",
            "           1       0.70      0.30      0.42        23\n",
            "           2       0.65      0.79      0.71        14\n",
            "           3       0.63      0.57      0.60        30\n",
            "           4       0.58      0.61      0.59        18\n",
            "           5       0.00      0.00      0.00         1\n",
            "           6       0.94      0.89      0.91        18\n",
            "           7       1.00      0.50      0.67         2\n",
            "           8       0.00      0.00      0.00         3\n",
            "           9       0.79      0.96      0.87        28\n",
            "          10       0.86      0.67      0.75        18\n",
            "          11       0.00      0.00      0.00         1\n",
            "          12       0.64      0.79      0.70        56\n",
            "          13       0.56      0.45      0.50        20\n",
            "          14       0.00      0.00      0.00         2\n",
            "          15       0.66      0.68      0.67        28\n",
            "          16       0.00      0.00      0.00         1\n",
            "          17       0.76      0.86      0.81       189\n",
            "          18       0.00      0.00      0.00         1\n",
            "          19       0.50      0.59      0.54        44\n",
            "          20       0.00      0.00      0.00         4\n",
            "          21       0.95      0.98      0.96      1087\n",
            "          22       0.33      0.40      0.36        10\n",
            "          23       0.59      0.76      0.67        17\n",
            "          24       0.83      0.86      0.85        35\n",
            "          25       0.71      0.67      0.69        30\n",
            "          26       0.77      0.78      0.78       149\n",
            "          27       0.00      0.00      0.00         4\n",
            "          28       0.00      0.00      0.00         1\n",
            "          29       0.33      0.60      0.43         5\n",
            "          30       1.00      0.33      0.50         6\n",
            "          31       0.75      0.75      0.75         4\n",
            "          32       1.00      0.57      0.73         7\n",
            "          33       0.00      0.00      0.00         1\n",
            "          34       0.59      0.60      0.59       131\n",
            "          35       0.56      0.75      0.64        12\n",
            "          36       0.56      0.36      0.43        14\n",
            "          37       0.00      0.00      0.00         1\n",
            "          38       0.77      0.81      0.79        21\n",
            "          39       0.00      0.00      0.00         2\n",
            "          40       0.80      0.29      0.42        14\n",
            "          41       0.75      1.00      0.86         3\n",
            "          42       0.00      0.00      0.00         1\n",
            "          43       0.48      0.54      0.51        24\n",
            "          44       1.00      0.33      0.50         6\n",
            "          45       0.46      0.32      0.37        19\n",
            "          46       0.63      0.72      0.67       179\n",
            "          47       0.63      0.79      0.70        34\n",
            "          48       0.50      0.25      0.33         4\n",
            "          49       0.47      0.50      0.48        30\n",
            "          50       0.00      0.00      0.00         1\n",
            "          51       0.00      0.00      0.00         2\n",
            "          52       0.00      0.00      0.00         2\n",
            "          53       1.00      0.17      0.29         6\n",
            "          54       0.45      0.64      0.53        47\n",
            "          55       0.78      0.64      0.70        11\n",
            "          56       0.00      0.00      0.00         1\n",
            "          57       0.67      0.40      0.50        10\n",
            "          58       0.00      0.00      0.00         1\n",
            "          59       0.80      0.33      0.47        12\n",
            "          60       1.00      0.14      0.25         7\n",
            "          61       0.00      0.00      0.00         3\n",
            "          62       0.00      0.00      0.00         3\n",
            "          63       0.00      0.00      0.00         1\n",
            "          64       0.00      0.00      0.00         3\n",
            "          65       0.67      0.44      0.53         9\n",
            "          66       0.75      0.67      0.71        18\n",
            "          67       1.00      0.50      0.67         2\n",
            "          68       0.78      0.29      0.42        24\n",
            "          69       0.88      0.58      0.70        12\n",
            "          70       0.00      0.00      0.00         1\n",
            "          71       0.78      0.70      0.73        89\n",
            "          72       0.67      0.25      0.36         8\n",
            "          73       0.50      0.40      0.44        10\n",
            "          74       1.00      0.31      0.47        13\n",
            "          75       0.50      0.55      0.52        11\n",
            "          76       0.51      0.67      0.58        33\n",
            "          77       0.17      0.09      0.12        11\n",
            "          78       0.85      0.81      0.83        36\n",
            "          79       0.00      0.00      0.00         1\n",
            "          80       0.00      0.00      0.00         2\n",
            "          81       0.50      0.20      0.29         5\n",
            "          82       0.00      0.00      0.00         4\n",
            "          83       1.00      0.25      0.40        12\n",
            "          84       0.50      0.66      0.57       117\n",
            "          85       0.58      0.41      0.48        37\n",
            "          86       0.85      0.79      0.82        71\n",
            "          87       0.80      0.40      0.53        10\n",
            "          88       0.29      0.29      0.29        14\n",
            "          89       0.90      0.69      0.78        13\n",
            "\n",
            "   micro avg       0.79      0.79      0.79      3744\n",
            "   macro avg       0.50      0.40      0.42      3744\n",
            "weighted avg       0.79      0.79      0.78      3744\n",
            " samples avg       0.81      0.85      0.82      3744\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rmz7Vycr6BvZ"
      },
      "source": [
        "# Naive Bayes Classifier"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qib7wcxa5vf8"
      },
      "source": [
        "from sklearn.naive_bayes import GaussianNB\r\n",
        "from sklearn.metrics import classification_report\r\n",
        "from sklearn.multiclass import OneVsRestClassifier"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aVQ3fFc-L8u3"
      },
      "source": [
        "## Fit and Predict Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "__2S1xz3L7iB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a5f83b45-69ac-4976-eea5-8d245fe31380"
      },
      "source": [
        "gnb = OneVsRestClassifier(GaussianNB())\r\n",
        "gnb.fit(x_train, y_train)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "OneVsRestClassifier(estimator=GaussianNB(priors=None, var_smoothing=1e-09),\n",
              "                    n_jobs=None)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 71
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_cYJDqV96I6T"
      },
      "source": [
        "y_pred = gnb.predict(x_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y-D3XgyIL3VW"
      },
      "source": [
        "## Classification report on testing data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FxJfnEH_6QLP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "89f7724f-5449-4a4d-9b88-b8fab33be331"
      },
      "source": [
        "print(\"Naive Bayes Classifier Result word on Train\")\r\n",
        "#print(classification_report(nbClassifier.predict(X_train) , y_train))\r\n",
        "print(classification_report(y_pred = y_pred , y_true= y_test))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Naive Bayes Classifier Result word on Train\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.32      0.91      0.47       719\n",
            "           1       0.02      0.61      0.05        23\n",
            "           2       0.01      0.79      0.02        14\n",
            "           3       0.04      0.47      0.08        30\n",
            "           4       0.06      0.72      0.10        18\n",
            "           5       0.00      0.00      0.00         1\n",
            "           6       0.02      0.28      0.03        18\n",
            "           7       0.00      0.00      0.00         2\n",
            "           8       0.02      0.67      0.05         3\n",
            "           9       0.03      0.32      0.05        28\n",
            "          10       0.04      0.67      0.07        18\n",
            "          11       0.00      0.00      0.00         1\n",
            "          12       0.05      0.36      0.09        56\n",
            "          13       0.04      0.55      0.08        20\n",
            "          14       0.00      0.00      0.00         2\n",
            "          15       0.07      0.54      0.12        28\n",
            "          16       1.00      1.00      1.00         1\n",
            "          17       0.15      0.35      0.21       189\n",
            "          18       0.00      0.00      0.00         1\n",
            "          19       0.06      0.32      0.10        44\n",
            "          20       0.00      0.25      0.00         4\n",
            "          21       0.46      0.93      0.62      1087\n",
            "          22       0.11      0.70      0.20        10\n",
            "          23       0.02      0.35      0.03        17\n",
            "          24       0.08      0.77      0.15        35\n",
            "          25       0.14      0.80      0.24        30\n",
            "          26       0.14      0.36      0.20       149\n",
            "          27       0.00      0.00      0.00         4\n",
            "          28       0.00      0.00      0.00         1\n",
            "          29       0.01      0.20      0.03         5\n",
            "          30       0.00      0.50      0.01         6\n",
            "          31       0.03      0.50      0.06         4\n",
            "          32       0.04      0.71      0.07         7\n",
            "          33       0.00      0.00      0.00         1\n",
            "          34       0.19      0.33      0.24       131\n",
            "          35       0.01      0.25      0.02        12\n",
            "          36       0.01      0.29      0.02        14\n",
            "          37       0.01      1.00      0.01         1\n",
            "          38       0.05      0.48      0.10        21\n",
            "          39       0.00      0.00      0.00         2\n",
            "          40       0.02      0.57      0.03        14\n",
            "          41       0.00      1.00      0.01         3\n",
            "          42       0.00      0.00      0.00         1\n",
            "          43       0.04      0.46      0.07        24\n",
            "          44       0.22      0.33      0.27         6\n",
            "          45       0.08      0.63      0.15        19\n",
            "          46       0.15      0.30      0.20       179\n",
            "          47       0.08      0.38      0.13        34\n",
            "          48       0.00      0.00      0.00         4\n",
            "          49       0.02      0.23      0.04        30\n",
            "          50       0.00      0.00      0.00         1\n",
            "          51       0.00      0.00      0.00         2\n",
            "          52       0.00      0.00      0.00         2\n",
            "          53       0.14      0.50      0.21         6\n",
            "          54       0.06      0.43      0.10        47\n",
            "          55       0.01      0.73      0.01        11\n",
            "          56       0.00      0.00      0.00         1\n",
            "          57       0.04      0.40      0.07        10\n",
            "          58       0.00      0.00      0.00         1\n",
            "          59       0.03      0.58      0.05        12\n",
            "          60       0.00      0.00      0.00         7\n",
            "          61       0.00      0.00      0.00         3\n",
            "          62       0.00      0.00      0.00         3\n",
            "          63       0.00      0.00      0.00         1\n",
            "          64       0.00      0.00      0.00         3\n",
            "          65       0.05      0.33      0.09         9\n",
            "          66       0.07      0.56      0.13        18\n",
            "          67       0.01      1.00      0.01         2\n",
            "          68       0.09      0.54      0.15        24\n",
            "          69       0.01      0.17      0.01        12\n",
            "          70       0.00      0.00      0.00         1\n",
            "          71       0.22      0.80      0.34        89\n",
            "          72       0.04      0.50      0.08         8\n",
            "          73       0.02      0.50      0.04        10\n",
            "          74       0.03      0.62      0.06        13\n",
            "          75       0.03      0.73      0.06        11\n",
            "          76       0.04      0.45      0.08        33\n",
            "          77       0.00      0.36      0.01        11\n",
            "          78       0.03      0.28      0.05        36\n",
            "          79       0.00      0.00      0.00         1\n",
            "          80       0.00      0.00      0.00         2\n",
            "          81       0.01      0.20      0.01         5\n",
            "          82       0.00      0.25      0.01         4\n",
            "          83       0.01      0.25      0.02        12\n",
            "          84       0.14      0.48      0.21       117\n",
            "          85       0.09      0.70      0.15        37\n",
            "          86       0.07      0.37      0.12        71\n",
            "          87       0.04      0.30      0.08        10\n",
            "          88       0.01      0.29      0.03        14\n",
            "          89       0.02      0.69      0.03        13\n",
            "\n",
            "   micro avg       0.10      0.67      0.17      3744\n",
            "   macro avg       0.06      0.38      0.08      3744\n",
            "weighted avg       0.24      0.67      0.34      3744\n",
            " samples avg       0.24      0.71      0.31      3744\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ],
          "name": "stderr"
        }
      ]
    }
  ]
}